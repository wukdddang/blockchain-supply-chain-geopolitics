#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì‹¤íŒ¨í•œ ë°ì´í„° ìˆ˜ì§‘ ì¬ì‹œë„ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    python retry_failed_collection.py --summary-file collection_summary_20250911_141654.json
    python retry_failed_collection.py --summary-file collection_summary_20250911_141654.json --items oil
    python retry_failed_collection.py --summary-file collection_summary_20250911_141654.json --max-retries 3
"""

import json
import argparse
import sys
import os
from datetime import datetime
import time
from pathlib import Path

# bulk_data_collectorì—ì„œ í´ë˜ìŠ¤ ê°€ì ¸ì˜¤ê¸°
try:
    from bulk_data_collector import BulkDataCollector
except ImportError:
    print("âŒ bulk_data_collector.pyë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    sys.exit(1)


def load_failed_requests(summary_file):
    """ìˆ˜ì§‘ ìš”ì•½ íŒŒì¼ì—ì„œ ì‹¤íŒ¨í•œ ìš”ì²­ë“¤ì„ ë¡œë“œ"""
    try:
        with open(summary_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return data.get('failed_requests', [])
    except FileNotFoundError:
        print(f"âŒ ìš”ì•½ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {summary_file}")
        return []
    except json.JSONDecodeError:
        print(f"âŒ JSON íŒŒì¼ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤: {summary_file}")
        return []


def filter_failed_requests(failed_requests, target_items=None):
    """íŠ¹ì • í’ˆëª©ì˜ ì‹¤íŒ¨ ìš”ì²­ë§Œ í•„í„°ë§"""
    if not target_items:
        return failed_requests
    
    # í’ˆëª© ê·¸ë£¹ ë§¤í•‘
    item_groups = {
        'semiconductor': ['semiconductor_8541', 'semiconductor_8542'],
        'oil': ['oil'],
        'copper': ['copper'],
        'plastic': ['plastic_3901', 'plastic_3902', 'plastic_3903']
    }
    
    # ëŒ€ìƒ í’ˆëª©ë“¤ì„ ê°œë³„ í’ˆëª©ìœ¼ë¡œ í™•ì¥
    expanded_items = []
    for item in target_items:
        if item in item_groups:
            expanded_items.extend(item_groups[item])
        else:
            expanded_items.append(item)
    
    return [req for req in failed_requests if req.get('item') in expanded_items]


def retry_failed_collection(failed_requests, max_retries=2, delay=2.0):
    """ì‹¤íŒ¨í•œ ìš”ì²­ë“¤ì„ ì¬ì‹œë„"""
    if not failed_requests:
        print("ğŸ“ ì¬ì‹œë„í•  ì‹¤íŒ¨ ìš”ì²­ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ”„ {len(failed_requests)}ê°œì˜ ì‹¤íŒ¨í•œ ìš”ì²­ì„ ì¬ì‹œë„í•©ë‹ˆë‹¤...")
    
    # BulkDataCollector ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    collector = BulkDataCollector()
    
    # ê²°ê³¼ ì €ì¥
    retry_results = {
        'retry_date': datetime.now().isoformat(),
        'original_failures': len(failed_requests),
        'successful_retries': [],
        'still_failed': [],
        'max_retries': max_retries
    }
    
    for i, failed_req in enumerate(failed_requests, 1):
        year = failed_req.get('year')
        item = failed_req.get('item')
        reporter_name = failed_req.get('reporter_name')
        partner_name = failed_req.get('partner_name')
        
        print(f"\n[{i}/{len(failed_requests)}] ì¬ì‹œë„: {year}ë…„ {item} {reporter_name}â†’{partner_name}")
        
        # êµ­ê°€ ì½”ë“œ ì°¾ê¸° (MAJOR_TRADE_PAIRSì—ì„œ ê²€ìƒ‰)
        from bulk_data_collector import MAJOR_TRADE_PAIRS
        
        reporter_code = None
        partner_code = None
        
        for rep_code, part_code, rep_name, part_name in MAJOR_TRADE_PAIRS:
            if rep_name == reporter_name:
                reporter_code = rep_code
            if rep_name == partner_name:
                partner_code = rep_code
            if part_name == reporter_name:
                reporter_code = part_code
            if part_name == partner_name:
                partner_code = part_code
        
        if not reporter_code or not partner_code:
            print(f"   âŒ êµ­ê°€ ì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {reporter_name}, {partner_name}")
            retry_results['still_failed'].append(failed_req)
            continue
        
        # ì¬ì‹œë„ ë¡œì§
        success = False
        for attempt in range(max_retries):
            try:
                print(f"   ğŸ”„ ì‹œë„ {attempt + 1}/{max_retries}...")
                
                # ë°ì´í„° ìˆ˜ì§‘ ì‹œë„
                result = collector.collect_single_data(
                    year=year,
                    item=item,
                    reporter_code=reporter_code,
                    partner_code=partner_code,
                    reporter_name=reporter_name,
                    partner_name=partner_name
                )
                
                if result['success']:
                    print(f"   âœ… ì„±ê³µ! ë ˆì½”ë“œ: {result.get('records', 0)}")
                    retry_results['successful_retries'].append({
                        'year': year,
                        'item': item,
                        'reporter_name': reporter_name,
                        'partner_name': partner_name,
                        'records': result.get('records', 0),
                        'trade_value': result.get('trade_value', 0),
                        'attempt': attempt + 1
                    })
                    success = True
                    break
                else:
                    print(f"   âš ï¸  ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
                    
            except Exception as e:
                print(f"   âŒ ì‹œë„ {attempt + 1} ì˜ˆì™¸ ë°œìƒ: {str(e)}")
            
            # ì¬ì‹œë„ ì „ ëŒ€ê¸°
            if attempt < max_retries - 1:
                time.sleep(delay)
        
        if not success:
            print(f"   âŒ ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨")
            retry_results['still_failed'].append(failed_req)
        
        # ìš”ì²­ ê°„ ëŒ€ê¸°
        if i < len(failed_requests):
            time.sleep(delay)
    
    # ê²°ê³¼ ì €ì¥
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    result_file = f"./data/output/retry_results_{timestamp}.json"
    
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump(retry_results, f, ensure_ascii=False, indent=2)
    
    # ê²°ê³¼ ìš”ì•½
    successful = len(retry_results['successful_retries'])
    still_failed = len(retry_results['still_failed'])
    
    print(f"\nğŸ‰ ì¬ì‹œë„ ì™„ë£Œ!")
    print(f"   âœ… ì„±ê³µ: {successful}ê°œ")
    print(f"   âŒ ì—¬ì „íˆ ì‹¤íŒ¨: {still_failed}ê°œ")
    print(f"   ğŸ“Š ì„±ê³µë¥ : {successful/(successful+still_failed)*100:.1f}%")
    print(f"   ğŸ“ ê²°ê³¼ íŒŒì¼: {result_file}")
    
    return retry_results


def main():
    parser = argparse.ArgumentParser(description="ì‹¤íŒ¨í•œ ë°ì´í„° ìˆ˜ì§‘ ì¬ì‹œë„")
    parser.add_argument("--summary-file", required=True, 
                       help="ìˆ˜ì§‘ ìš”ì•½ JSON íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--items", nargs="+", 
                       choices=['semiconductor', 'oil', 'copper', 'plastic'],
                       help="ì¬ì‹œë„í•  í’ˆëª©ë“¤ (ê¸°ë³¸ê°’: ëª¨ë“  í’ˆëª©)")
    parser.add_argument("--max-retries", type=int, default=2,
                       help="ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ (ê¸°ë³¸ê°’: 2)")
    parser.add_argument("--delay", type=float, default=2.0,
                       help="ìš”ì²­ ê°„ ëŒ€ê¸° ì‹œê°„ (ì´ˆ, ê¸°ë³¸ê°’: 2.0)")
    
    args = parser.parse_args()
    
    # ì‹¤íŒ¨í•œ ìš”ì²­ë“¤ ë¡œë“œ
    failed_requests = load_failed_requests(args.summary_file)
    if not failed_requests:
        print("ğŸ“ ì‹¤íŒ¨í•œ ìš”ì²­ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ“‹ ì´ {len(failed_requests)}ê°œì˜ ì‹¤íŒ¨í•œ ìš”ì²­ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    
    # í’ˆëª©ë³„ í•„í„°ë§
    if args.items:
        failed_requests = filter_failed_requests(failed_requests, args.items)
        print(f"ğŸ¯ {args.items} í’ˆëª©ìœ¼ë¡œ í•„í„°ë§: {len(failed_requests)}ê°œ")
    
    if not failed_requests:
        print("ğŸ“ í•„í„°ë§ í›„ ì¬ì‹œë„í•  ìš”ì²­ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì¬ì‹œë„ ì‹¤í–‰
    retry_failed_collection(failed_requests, args.max_retries, args.delay)


if __name__ == "__main__":
    main()
