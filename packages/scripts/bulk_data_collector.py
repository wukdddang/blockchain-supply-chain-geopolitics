#!/usr/bin/env python3
"""
2018-2024ë…„ ëª¨ë“  í’ˆëª© ëŒ€ëŸ‰ ë°ì´í„° ìˆ˜ì§‘ê¸°

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì—¬ëŸ¬ ì—°ë„ì™€ í’ˆëª©ì— ëŒ€í•´ ìë™ìœ¼ë¡œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
ì£¼ìš” ë¬´ì—­ ê´€ê³„(ë¯¸êµ­-ì¤‘êµ­, ë¯¸êµ­-ì¼ë³¸, ë…ì¼-ì¤‘êµ­ ë“±)ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python bulk_data_collector.py --start-year 2018 --end-year 2024
    python bulk_data_collector.py --start-year 2020 --end-year 2022 --items semiconductor oil
"""

import comtradeapicall
import pandas as pd
import geopandas as gpd
from shapely.geometry import LineString
import json
import os
import sys
import argparse
import time
from datetime import datetime
from typing import List, Dict, Tuple

# í’ˆëª©ë³„ HS Code ì •ì˜ (GUIDE.md ê¸°ì¤€) - ê°œë³„ ì½”ë“œë¡œ ë¶„ë¦¬
COMMODITY_MAP = {
    "semiconductor_8541": "8541",      # ë‹¤ì´ì˜¤ë“œ, íŠ¸ëœì§€ìŠ¤í„° ë“±
    "semiconductor_8542": "8542",      # ì§‘ì íšŒë¡œ
    "oil": "2709",                     # ì„ìœ  ë° ì—­ì²­ìœ  (ì›ìœ )
    "copper": "7403",                  # ì •ì œëœ êµ¬ë¦¬ ë° êµ¬ë¦¬ í•©ê¸ˆ
    "plastic_3901": "3901",            # ê¸°ì´ˆ í”Œë¼ìŠ¤í‹± í´ë¦¬ë¨¸ (ì—í‹¸ë Œ)
    "plastic_3902": "3902",            # ê¸°ì´ˆ í”Œë¼ìŠ¤í‹± í´ë¦¬ë¨¸ (í”„ë¡œí•„ë Œ)
    "plastic_3903": "3903"             # ê¸°ì´ˆ í”Œë¼ìŠ¤í‹± í´ë¦¬ë¨¸ (ìŠ¤í‹°ë Œ)
}

# í’ˆëª© ê·¸ë£¹ ì •ì˜ (ì‚¬ìš©ì í¸ì˜ë¥¼ ìœ„í•´)
COMMODITY_GROUPS = {
    "semiconductor": ["semiconductor_8541", "semiconductor_8542"],
    "oil": ["oil"],
    "copper": ["copper"],
    "plastic": ["plastic_3901", "plastic_3902", "plastic_3903"]
}

# ì£¼ìš” ë¬´ì—­ ê´€ê³„ (ë³´ê³ êµ­-íŒŒíŠ¸ë„ˆêµ­ ì¡°í•©)
MAJOR_TRADE_PAIRS = [
    ("842", "156", "USA", "China"),      # ë¯¸êµ­ â† ì¤‘êµ­
    ("842", "392", "USA", "Japan"),      # ë¯¸êµ­ â† ì¼ë³¸
    ("842", "276", "USA", "Germany"),    # ë¯¸êµ­ â† ë…ì¼
    ("842", "410", "USA", "Korea"),      # ë¯¸êµ­ â† í•œêµ­
    ("276", "156", "Germany", "China"),  # ë…ì¼ â† ì¤‘êµ­
    ("276", "392", "Germany", "Japan"),  # ë…ì¼ â† ì¼ë³¸
    ("392", "156", "Japan", "China"),    # ì¼ë³¸ â† ì¤‘êµ­
    ("410", "156", "Korea", "China"),    # í•œêµ­ â† ì¤‘êµ­
    ("410", "392", "Korea", "Japan"),    # í•œêµ­ â† ì¼ë³¸
    ("156", "842", "China", "USA"),      # ì¤‘êµ­ â† ë¯¸êµ­ (ì—­ë°©í–¥)
]

class BulkDataCollector:
    def __init__(self, output_dir="./data/output"):
        self.output_dir = output_dir
        self.country_coords = None
        self.collected_data = []
        self.failed_requests = []
        
        # ì¶œë ¥ ë””ë ‰í„°ë¦¬ ìƒì„±
        os.makedirs(output_dir, exist_ok=True)
        
        # ë¡œê·¸ íŒŒì¼ ì„¤ì •
        self.log_file = os.path.join(output_dir, f"bulk_collection_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt")
        
    def log_message(self, message: str, print_console: bool = True):
        """ë©”ì‹œì§€ë¥¼ ë¡œê·¸ íŒŒì¼ê³¼ ì½˜ì†”ì— ì¶œë ¥"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        log_entry = f"[{timestamp}] {message}"
        
        if print_console:
            print(log_entry)
        
        with open(self.log_file, "a", encoding="utf-8") as f:
            f.write(log_entry + "\n")
    
    def load_country_coordinates(self):
        """êµ­ê°€ë³„ ì¤‘ì‹¬ì  ë°ì´í„° ë¡œë”©"""
        try:
            self.log_message("êµ­ê°€ë³„ ì¤‘ì‹¬ì  ë°ì´í„° ë¡œë”© ì¤‘...")
            world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))
            world['centroid'] = world.geometry.centroid
            world['centroid_lon'] = world['centroid'].x
            world['centroid_lat'] = world['centroid'].y
            
            # êµ­ê°€ ì½”ë“œ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„±
            country_coords = {}
            for idx, row in world.iterrows():
                if pd.notna(row['iso_a3']):
                    country_coords[row['iso_a3']] = {
                        'name': row['name'],
                        'lon': row['centroid_lon'],
                        'lat': row['centroid_lat']
                    }
                if pd.notna(row['name']):
                    country_coords[row['name']] = {
                        'name': row['name'],
                        'lon': row['centroid_lon'],
                        'lat': row['centroid_lat']
                    }
            
            # UN Comtrade API íŠ¹ìˆ˜ êµ­ê°€ëª… ë§¤í•‘ ì¶”ê°€
            comtrade_mappings = {
                'Rep. of Korea': country_coords.get('South Korea', country_coords.get('Korea')),
                'China, Hong Kong SAR': country_coords.get('Hong Kong'),
                'China, Macao SAR': country_coords.get('Macao'),
                'United States of America': country_coords.get('United States of America'),
                'Russian Federation': country_coords.get('Russia'),
                'United Kingdom': country_coords.get('United Kingdom'),
                'Viet Nam': country_coords.get('Vietnam'),
                'Iran (Islamic Rep. of)': country_coords.get('Iran'),
                'Venezuela (Boliv. Rep. of)': country_coords.get('Venezuela'),
                'Bolivia (Plurin. State of)': country_coords.get('Bolivia'),
                'Tanzania (United Rep. of)': country_coords.get('Tanzania'),
                'Moldova (Rep. of)': country_coords.get('Moldova'),
                'Macedonia (North)': country_coords.get('North Macedonia'),
                'Czechia': country_coords.get('Czech Rep.', country_coords.get('Czech Republic')),
                'TÃ¼rkiye': country_coords.get('Turkey')
            }
            
            # ë§¤í•‘ ì¶”ê°€ (Noneì´ ì•„ë‹Œ ê²½ìš°ë§Œ)
            for comtrade_name, coords in comtrade_mappings.items():
                if coords:
                    country_coords[comtrade_name] = coords
            
            self.country_coords = country_coords
            self.log_message(f"êµ­ê°€ ì¢Œí‘œ ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(country_coords)}ê°œ êµ­ê°€ (UN Comtrade ë§¤í•‘ í¬í•¨)")
            return True
            
        except Exception as e:
            self.log_message(f"êµ­ê°€ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
            return False
    
    def collect_single_data(self, year: int, item: str, reporter_code: str, partner_code: str, 
                           reporter_name: str, partner_name: str) -> Dict:
        """ë‹¨ì¼ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            self.log_message(f"ìˆ˜ì§‘ ì¤‘: {year}ë…„ {item} {reporter_name}â†{partner_name}", print_console=False)
            
            # API í˜¸ì¶œ
            data = comtradeapicall.getFinalData(
                subscription_key=None,
                typeCode='C',
                freqCode='A',
                clCode='HS',
                period=str(year),
                reporterCode=reporter_code,
                cmdCode=COMMODITY_MAP[item],
                flowCode='M',  # ìˆ˜ì…
                partnerCode=partner_code,
                partner2Code='0',
                customsCode='C00',
                motCode='0',
                maxRecords=100,
                format_output='JSON',
                includeDesc=True
            )
            
            if data is not None and isinstance(data, pd.DataFrame) and not data.empty:
                return {
                    'success': True,
                    'data': data,
                    'year': year,
                    'item': item,
                    'reporter_code': reporter_code,
                    'partner_code': partner_code,
                    'reporter_name': reporter_name,
                    'partner_name': partner_name,
                    'records': len(data)
                }
            elif data is not None and isinstance(data, list) and data:
                return {
                    'success': True,
                    'data': pd.DataFrame(data),
                    'year': year,
                    'item': item,
                    'reporter_code': reporter_code,
                    'partner_code': partner_code,
                    'reporter_name': reporter_name,
                    'partner_name': partner_name,
                    'records': len(data)
                }
            else:
                return {
                    'success': False,
                    'error': 'No data returned',
                    'year': year,
                    'item': item,
                    'reporter_name': reporter_name,
                    'partner_name': partner_name
                }
                
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'year': year,
                'item': item,
                'reporter_name': reporter_name,
                'partner_name': partner_name
            }
    
    def process_to_geojson(self, df: pd.DataFrame, item_name: str, year: int, 
                          reporter_name: str, partner_name: str) -> Dict:
        """ë°ì´í„°ë¥¼ GeoJSONìœ¼ë¡œ ë³€í™˜"""
        try:
            features = []
            processed_count = 0
            
            for idx, row in df.iterrows():
                try:
                    # êµ­ê°€ëª… ì¶”ì¶œ
                    reporter_desc = row.get('reporterDesc', reporter_name)
                    partner_desc = row.get('partnerDesc', partner_name)
                    
                    # ì¢Œí‘œ ì°¾ê¸°
                    reporter_coords = None
                    partner_coords = None
                    
                    # ISO ì½”ë“œë¡œ ì°¾ê¸°
                    if row.get('reporterCodeIsoAlpha3'):
                        reporter_coords = self.country_coords.get(row['reporterCodeIsoAlpha3'])
                    if row.get('PartnerCodeIsoAlpha3'):
                        partner_coords = self.country_coords.get(row['PartnerCodeIsoAlpha3'])
                    
                    # ì´ë¦„ìœ¼ë¡œ ì°¾ê¸°
                    if not reporter_coords:
                        reporter_coords = self.country_coords.get(reporter_desc)
                    if not partner_coords:
                        partner_coords = self.country_coords.get(partner_desc)
                    
                    if reporter_coords and partner_coords:
                        # LineString ìƒì„± (íŒŒíŠ¸ë„ˆêµ­ -> ë³´ê³ êµ­)
                        line = LineString([
                            (partner_coords['lon'], partner_coords['lat']),
                            (reporter_coords['lon'], reporter_coords['lat'])
                        ])
                        
                        # ì†ì„± ì •ë³´
                        properties = {
                            'reporter_name': reporter_desc,
                            'partner_name': partner_desc,
                            'trade_value': float(row.get('primaryValue', 0)),
                            'net_weight': float(row.get('netWgt', 0)) if pd.notna(row.get('netWgt')) else 0,
                            'quantity': float(row.get('qty', 0)) if pd.notna(row.get('qty')) else 0,
                            'item': item_name,
                            'year': year,
                            'flow_direction': f"{partner_desc} â†’ {reporter_desc}"
                        }
                        
                        feature = {
                            'type': 'Feature',
                            'geometry': line.__geo_interface__,
                            'properties': properties
                        }
                        
                        features.append(feature)
                        processed_count += 1
                        
                except Exception as e:
                    continue
            
            geojson = {
                'type': 'FeatureCollection',
                'features': features,
                'metadata': {
                    'item': item_name,
                    'year': year,
                    'reporter': reporter_name,
                    'partner': partner_name,
                    'total_flows': len(features),
                    'processed_records': processed_count,
                    'total_records': len(df),
                    'created_at': datetime.now().isoformat()
                }
            }
            
            return geojson
            
        except Exception as e:
            self.log_message(f"GeoJSON ë³€í™˜ ì˜¤ë¥˜: {e}")
            return None
    
    def save_data(self, result: Dict, geojson: Dict = None):
        """ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        try:
            # íŒŒì¼ëª… ìƒì„±
            base_filename = f"trade_{result['item']}_{result['year']}_{result['reporter_code']}_{result['partner_code']}"
            
            # CSV ì €ì¥
            csv_path = os.path.join(self.output_dir, f"{base_filename}.csv")
            result['data'].to_csv(csv_path, index=False, encoding='utf-8-sig')
            
            # GeoJSON ì €ì¥
            if geojson:
                geojson_path = os.path.join(self.output_dir, f"{base_filename}.geojson")
                with open(geojson_path, 'w', encoding='utf-8') as f:
                    json.dump(geojson, f, indent=2, ensure_ascii=False)
            
            return True
            
        except Exception as e:
            self.log_message(f"íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {e}")
            return False
    
    def collect_bulk_data(self, start_year: int, end_year: int, items: List[str] = None, 
                         trade_pairs: List[Tuple] = None, delay_seconds: float = 1.0):
        """ëŒ€ëŸ‰ ë°ì´í„° ìˆ˜ì§‘"""
        
        # ê¸°ë³¸ê°’ ì„¤ì • ë° í’ˆëª© ê·¸ë£¹ í™•ì¥
        if items is None:
            items = list(COMMODITY_GROUPS.keys())
        if trade_pairs is None:
            trade_pairs = MAJOR_TRADE_PAIRS
        
        # í’ˆëª© ê·¸ë£¹ì„ ê°œë³„ í’ˆëª©ìœ¼ë¡œ í™•ì¥
        expanded_items = []
        for item in items:
            if item in COMMODITY_GROUPS:
                expanded_items.extend(COMMODITY_GROUPS[item])
            elif item in COMMODITY_MAP:
                expanded_items.append(item)
            else:
                self.log_message(f"âš ï¸  ì•Œ ìˆ˜ ì—†ëŠ” í’ˆëª©: {item}")
        
        items = expanded_items
        
        self.log_message("=== ëŒ€ëŸ‰ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ ===")
        self.log_message(f"ì—°ë„ ë²”ìœ„: {start_year}-{end_year}")
        self.log_message(f"í’ˆëª©: {', '.join(items)}")
        self.log_message(f"ë¬´ì—­ ê´€ê³„: {len(trade_pairs)}ê°œ")
        
        # êµ­ê°€ ì¢Œí‘œ ë¡œë”©
        if not self.load_country_coordinates():
            self.log_message("âŒ êµ­ê°€ ì¢Œí‘œ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨")
            return False
        
        # ì´ ì‘ì—… ìˆ˜ ê³„ì‚°
        total_tasks = len(range(start_year, end_year + 1)) * len(items) * len(trade_pairs)
        self.log_message(f"ì´ {total_tasks}ê°œ ì‘ì—… ì˜ˆì •")
        
        completed_tasks = 0
        successful_collections = 0
        
        # ì—°ë„ë³„ ìˆ˜ì§‘
        for year in range(start_year, end_year + 1):
            self.log_message(f"\nğŸ“… {year}ë…„ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
            
            # í’ˆëª©ë³„ ìˆ˜ì§‘
            for item in items:
                self.log_message(f"  ğŸ“¦ {item} ìˆ˜ì§‘ ì¤‘...")
                
                # ë¬´ì—­ ê´€ê³„ë³„ ìˆ˜ì§‘
                for reporter_code, partner_code, reporter_name, partner_name in trade_pairs:
                    completed_tasks += 1
                    
                    # ì§„í–‰ë¥  í‘œì‹œ
                    progress = (completed_tasks / total_tasks) * 100
                    self.log_message(f"    [{completed_tasks}/{total_tasks}] ({progress:.1f}%) {reporter_name}â†{partner_name}", print_console=False)
                    
                    # ë°ì´í„° ìˆ˜ì§‘
                    result = self.collect_single_data(
                        year, item, reporter_code, partner_code, reporter_name, partner_name
                    )
                    
                    if result['success']:
                        # GeoJSON ë³€í™˜
                        geojson = self.process_to_geojson(
                            result['data'], item, year, reporter_name, partner_name
                        )
                        
                        # íŒŒì¼ ì €ì¥
                        if self.save_data(result, geojson):
                            successful_collections += 1
                            self.collected_data.append(result)
                            
                            # ì„±ê³µ ë¡œê·¸
                            trade_value = result['data']['primaryValue'].sum() if 'primaryValue' in result['data'].columns else 0
                            self.log_message(f"      âœ… ${trade_value:,.0f} ({result['records']} ë ˆì½”ë“œ)", print_console=False)
                        else:
                            self.failed_requests.append(result)
                    else:
                        self.failed_requests.append(result)
                        self.log_message(f"      âŒ {result.get('error', 'Unknown error')}", print_console=False)
                    
                    # API ì œí•œì„ ìœ„í•œ ì§€ì—°
                    if delay_seconds > 0:
                        time.sleep(delay_seconds)
        
        # ìµœì¢… ê²°ê³¼ ìš”ì•½
        self.log_message(f"\nğŸ‰ ëŒ€ëŸ‰ ìˆ˜ì§‘ ì™„ë£Œ!")
        self.log_message(f"   - ì´ ì‘ì—…: {total_tasks}")
        self.log_message(f"   - ì„±ê³µ: {successful_collections}")
        self.log_message(f"   - ì‹¤íŒ¨: {len(self.failed_requests)}")
        self.log_message(f"   - ì„±ê³µë¥ : {(successful_collections/total_tasks)*100:.1f}%")
        
        # ì‹¤íŒ¨ ìš”ì•½
        if self.failed_requests:
            self.log_message(f"\nâŒ ì‹¤íŒ¨í•œ ìš”ì²­ë“¤:")
            failure_summary = {}
            for failed in self.failed_requests:
                key = f"{failed['year']}_{failed['item']}"
                if key not in failure_summary:
                    failure_summary[key] = 0
                failure_summary[key] += 1
            
            for key, count in failure_summary.items():
                self.log_message(f"   - {key}: {count}ê°œ")
        
        # ìˆ˜ì§‘ëœ ë°ì´í„° ìš”ì•½ ì €ì¥
        self.save_summary()
        
        return successful_collections > 0
    
    def save_summary(self):
        """ìˆ˜ì§‘ ìš”ì•½ ì •ë³´ ì €ì¥"""
        try:
            summary = {
                'collection_date': datetime.now().isoformat(),
                'total_successful': len(self.collected_data),
                'total_failed': len(self.failed_requests),
                'successful_collections': [],
                'failed_requests': self.failed_requests
            }
            
            # ì„±ê³µí•œ ìˆ˜ì§‘ ìš”ì•½
            for result in self.collected_data:
                trade_value = result['data']['primaryValue'].sum() if 'primaryValue' in result['data'].columns else 0
                summary['successful_collections'].append({
                    'year': result['year'],
                    'item': result['item'],
                    'reporter': result['reporter_name'],
                    'partner': result['partner_name'],
                    'records': result['records'],
                    'trade_value': float(trade_value)
                })
            
            # ìš”ì•½ íŒŒì¼ ì €ì¥
            summary_path = os.path.join(self.output_dir, f"collection_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
            with open(summary_path, 'w', encoding='utf-8') as f:
                json.dump(summary, f, indent=2, ensure_ascii=False)
            
            self.log_message(f"ğŸ“Š ìˆ˜ì§‘ ìš”ì•½ ì €ì¥: {summary_path}")
            
        except Exception as e:
            self.log_message(f"ìš”ì•½ ì €ì¥ ì˜¤ë¥˜: {e}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="2018-2024ë…„ ëª¨ë“  í’ˆëª© ëŒ€ëŸ‰ ë°ì´í„° ìˆ˜ì§‘",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python bulk_data_collector.py --start-year 2018 --end-year 2024
  python bulk_data_collector.py --start-year 2020 --end-year 2022 --items semiconductor oil
  python bulk_data_collector.py --start-year 2023 --end-year 2024 --delay 2.0

í’ˆëª© ì˜µì…˜:
  semiconductor : ë°˜ë„ì²´ (HS Code: 8541, 8542)
  oil          : ì›ìœ  (HS Code: 2709)
  copper       : êµ¬ë¦¬ (HS Code: 7403)
  plastic      : í”Œë¼ìŠ¤í‹± (HS Code: 3901, 3902, 3903)

ì£¼ìš” ë¬´ì—­ ê´€ê³„:
  ë¯¸êµ­â†ì¤‘êµ­, ë¯¸êµ­â†ì¼ë³¸, ë¯¸êµ­â†ë…ì¼, ë¯¸êµ­â†í•œêµ­
  ë…ì¼â†ì¤‘êµ­, ë…ì¼â†ì¼ë³¸, ì¼ë³¸â†ì¤‘êµ­, í•œêµ­â†ì¤‘êµ­, í•œêµ­â†ì¼ë³¸
        """
    )
    
    parser.add_argument("--start-year", type=int, default=2018, help="ì‹œì‘ ì—°ë„ (ê¸°ë³¸ê°’: 2018)")
    parser.add_argument("--end-year", type=int, default=2024, help="ì¢…ë£Œ ì—°ë„ (ê¸°ë³¸ê°’: 2024)")
    parser.add_argument("--items", nargs="+", choices=list(COMMODITY_GROUPS.keys()), 
                       default=list(COMMODITY_GROUPS.keys()), help="ìˆ˜ì§‘í•  í’ˆëª©ë“¤")
    parser.add_argument("--delay", type=float, default=1.0, 
                       help="API ìš”ì²­ ê°„ ì§€ì—° ì‹œê°„ (ì´ˆ, ê¸°ë³¸ê°’: 1.0)")
    parser.add_argument("--output-dir", type=str, default="./data/output",
                       help="ì¶œë ¥ ë””ë ‰í„°ë¦¬ (ê¸°ë³¸ê°’: ./data/output)")
    
    args = parser.parse_args()
    
    # ì…ë ¥ ê²€ì¦
    if args.start_year > args.end_year:
        print("âŒ ì‹œì‘ ì—°ë„ê°€ ì¢…ë£Œ ì—°ë„ë³´ë‹¤ í´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)
    
    if args.end_year > 2024:
        print("âš ï¸  2024ë…„ ì´í›„ ë°ì´í„°ëŠ” ì•„ì§ ì œê³µë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    # ëŒ€ëŸ‰ ìˆ˜ì§‘ê¸° ì‹¤í–‰
    collector = BulkDataCollector(args.output_dir)
    
    success = collector.collect_bulk_data(
        start_year=args.start_year,
        end_year=args.end_year,
        items=args.items,
        delay_seconds=args.delay
    )
    
    if success:
        print(f"\nğŸ‰ ëŒ€ëŸ‰ ë°ì´í„° ìˆ˜ì§‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {args.output_dir}")
        print(f"ğŸ“‹ ë¡œê·¸ íŒŒì¼: {collector.log_file}")
        sys.exit(0)
    else:
        print(f"\nâŒ ëŒ€ëŸ‰ ë°ì´í„° ìˆ˜ì§‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        sys.exit(1)

if __name__ == "__main__":
    main()
