#!/usr/bin/env python3
"""
UN Comtrade ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ì—¬ GeoJSONìœ¼ë¡œ ì €ì¥í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” UN Comtrade APIë¥¼ í†µí•´ ë¬´ì—­ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ
ì§€ë„ì—ì„œ ì‹œê°í™”í•  ìˆ˜ ìˆëŠ” GeoJSON í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python process_trade_data.py --year 2023 --item semiconductor
    python process_trade_data.py --year 2019 --item oil
"""

import pandas as pd
import requests
import geopandas as gpd
from shapely.geometry import LineString, Point
import json
import time
import argparse
import os
import sys
from typing import Dict, List, Optional, Tuple

# --- í’ˆëª©ë³„ HS Code ì •ì˜ ---
COMMODITY_MAP = {
    "semiconductor": "8541,8542",
    "oil": "2709", 
    "copper": "7403",
    "plastic": "3901,3902,3903"
}

# --- ì„¤ì • ---
OUTPUT_DIR = "./data/output"
API_ENDPOINT = "https://comtradeapi.un.org/public/v1/get"

def ensure_output_directory():
    """ì¶œë ¥ ë””ë ‰í„°ë¦¬ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ ìƒì„±"""
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    print(f"ì¶œë ¥ ë””ë ‰í„°ë¦¬ í™•ì¸ë¨: {OUTPUT_DIR}")

def get_country_centroids() -> gpd.GeoDataFrame:
    """êµ­ê°€ë³„ ì¤‘ì‹¬ì  ë°ì´í„°ë¥¼ ì¤€ë¹„"""
    try:
        print("êµ­ê°€ë³„ ì¤‘ì‹¬ì  ë°ì´í„° ë¡œë”© ì¤‘...")
        world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))
        world['centroid'] = world.geometry.centroid
        
        # ì¢Œí‘œ ì¶”ì¶œ
        world['centroid_lon'] = world['centroid'].x
        world['centroid_lat'] = world['centroid'].y
        
        country_centroids = world[['iso_a3', 'name', 'centroid_lon', 'centroid_lat']].copy()
        print(f"ì´ {len(country_centroids)}ê°œ êµ­ê°€ ë°ì´í„° ë¡œë”© ì™„ë£Œ")
        return country_centroids
    except Exception as e:
        print(f"êµ­ê°€ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
        return None

def fetch_trade_data(year: int, commodity_code: str) -> Optional[pd.DataFrame]:
    """UN Comtrade APIì—ì„œ ë¬´ì—­ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
    params = {
        "r": "all",        # ëª¨ë“  ë³´ê³  êµ­ê°€
        "p": "all",        # ëª¨ë“  íŒŒíŠ¸ë„ˆ êµ­ê°€
        "freq": "A",       # ì—°ê°„ ë°ì´í„°
        "ps": str(year),   # ê¸°ê°„ (ì—°ë„)
        "px": "HS",        # ë¶„ë¥˜ ì²´ê³„
        "cc": commodity_code,  # ìƒí’ˆ ì½”ë“œ
        "rg": "1",         # ë¬´ì—­ íë¦„ (1=ìˆ˜ì…, 2=ìˆ˜ì¶œ)
        "type": "C",       # ìƒí’ˆ
        "fmt": "json",     # JSON í˜•ì‹
        "max": "100000"    # ìµœëŒ€ ë ˆì½”ë“œ ìˆ˜
    }
    
    try:
        print(f"UN Comtrade API í˜¸ì¶œ ì¤‘... (ì—°ë„: {year}, ìƒí’ˆì½”ë“œ: {commodity_code})")
        response = requests.get(API_ENDPOINT, params=params, timeout=30)
        response.raise_for_status()
        
        data = response.json()
        if 'data' not in data or not data['data']:
            print(f"ê²½ê³ : {year}ë…„ ìƒí’ˆì½”ë“œ {commodity_code}ì— ëŒ€í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        df = pd.DataFrame(data['data'])
        print(f"APIë¡œë¶€í„° {len(df)}ê°œ ë ˆì½”ë“œ ìˆ˜ì‹  ì™„ë£Œ")
        return df
        
    except requests.exceptions.RequestException as e:
        print(f"API ìš”ì²­ ì‹¤íŒ¨: {e}")
        return None
    except Exception as e:
        print(f"ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

def process_trade_data(df: pd.DataFrame, country_centroids: gpd.GeoDataFrame) -> pd.DataFrame:
    """ë¬´ì—­ ë°ì´í„° ì „ì²˜ë¦¬ ë° ì§€ë¦¬ ì •ë³´ ê²°í•©"""
    try:
        print("ë¬´ì—­ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘...")
        
        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ê³  ì´ë¦„ ë³€ê²½
        columns_to_keep = {
            'rtCode': 'reporter_code',
            'rtTitle': 'reporter_name', 
            'ptCode': 'partner_code',
            'ptTitle': 'partner_name',
            'TradeValue': 'trade_value',
            'NetWeight': 'net_weight',
            'TradeQuantity': 'trade_quantity'
        }
        
        # ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        available_columns = {}
        for old_col, new_col in columns_to_keep.items():
            if old_col in df.columns:
                available_columns[old_col] = new_col
        
        if not available_columns:
            print("í•„ìš”í•œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        df_processed = df[list(available_columns.keys())].copy()
        df_processed = df_processed.rename(columns=available_columns)
        
        # ë¬´íš¨í•œ ë°ì´í„° ì œê±°
        if 'trade_value' in df_processed.columns:
            df_processed = df_processed[df_processed['trade_value'] > 0]
        
        # êµ­ê°€ ì½”ë“œë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        if 'reporter_code' in df_processed.columns:
            df_processed['reporter_code'] = df_processed['reporter_code'].astype(str)
        if 'partner_code' in df_processed.columns:
            df_processed['partner_code'] = df_processed['partner_code'].astype(str)
        
        print(f"ì „ì²˜ë¦¬ í›„ {len(df_processed)}ê°œ ë ˆì½”ë“œ ë‚¨ìŒ")
        
        # êµ­ê°€ ì¤‘ì‹¬ì  ë°ì´í„°ì™€ ê²°í•©
        print("êµ­ê°€ ì¤‘ì‹¬ì  ë°ì´í„°ì™€ ê²°í•© ì¤‘...")
        
        # Reporter êµ­ê°€ ì •ë³´ ê²°í•©
        df_with_coords = df_processed.merge(
            country_centroids[['name', 'centroid_lon', 'centroid_lat']], 
            left_on='reporter_name', 
            right_on='name', 
            how='left',
            suffixes=('', '_reporter')
        )
        df_with_coords = df_with_coords.rename(columns={
            'centroid_lon': 'reporter_lon',
            'centroid_lat': 'reporter_lat'
        })
        df_with_coords = df_with_coords.drop(columns=['name'], errors='ignore')
        
        # Partner êµ­ê°€ ì •ë³´ ê²°í•©
        df_with_coords = df_with_coords.merge(
            country_centroids[['name', 'centroid_lon', 'centroid_lat']], 
            left_on='partner_name', 
            right_on='name', 
            how='left',
            suffixes=('', '_partner')
        )
        df_with_coords = df_with_coords.rename(columns={
            'centroid_lon': 'partner_lon',
            'centroid_lat': 'partner_lat'
        })
        df_with_coords = df_with_coords.drop(columns=['name'], errors='ignore')
        
        # ì¢Œí‘œê°€ ì—†ëŠ” ë ˆì½”ë“œ ì œê±°
        df_final = df_with_coords.dropna(subset=['reporter_lon', 'reporter_lat', 'partner_lon', 'partner_lat'])
        
        print(f"ì¢Œí‘œ ê²°í•© í›„ {len(df_final)}ê°œ ë ˆì½”ë“œ ë‚¨ìŒ")
        return df_final
        
    except Exception as e:
        print(f"ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

def create_geojson(df: pd.DataFrame, item_name: str, year: int) -> Dict:
    """GeoJSON í˜•íƒœë¡œ ë³€í™˜"""
    try:
        print("GeoJSON ìƒì„± ì¤‘...")
        
        features = []
        
        for idx, row in df.iterrows():
            # LineString ìƒì„± (ìˆ˜ì¶œêµ­ -> ìˆ˜ì…êµ­)
            line = LineString([
                (row['partner_lon'], row['partner_lat']),  # ìˆ˜ì¶œêµ­ (partner)
                (row['reporter_lon'], row['reporter_lat'])  # ìˆ˜ì…êµ­ (reporter)
            ])
            
            # ì†ì„± ì •ë³´
            properties = {
                'reporter_name': row.get('reporter_name', 'Unknown'),
                'partner_name': row.get('partner_name', 'Unknown'),
                'trade_value': float(row.get('trade_value', 0)),
                'item': item_name,
                'year': year
            }
            
            # ì¶”ê°€ ì†ì„±ì´ ìˆìœ¼ë©´ í¬í•¨
            if 'net_weight' in row and pd.notna(row['net_weight']):
                properties['net_weight'] = float(row['net_weight'])
            if 'trade_quantity' in row and pd.notna(row['trade_quantity']):
                properties['trade_quantity'] = float(row['trade_quantity'])
            
            feature = {
                'type': 'Feature',
                'geometry': line.__geo_interface__,
                'properties': properties
            }
            
            features.append(feature)
        
        geojson = {
            'type': 'FeatureCollection',
            'features': features,
            'metadata': {
                'item': item_name,
                'year': year,
                'total_flows': len(features),
                'created_at': pd.Timestamp.now().isoformat()
            }
        }
        
        print(f"GeoJSON ìƒì„± ì™„ë£Œ: {len(features)}ê°œ ë¬´ì—­ íë¦„")
        return geojson
        
    except Exception as e:
        print(f"GeoJSON ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return None

def save_geojson(geojson: Dict, item_name: str, year: int) -> str:
    """GeoJSONì„ íŒŒì¼ë¡œ ì €ì¥"""
    try:
        filename = f"trade_flow_{item_name}_{year}.geojson"
        filepath = os.path.join(OUTPUT_DIR, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(geojson, f, indent=2, ensure_ascii=False)
        
        print(f"GeoJSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filepath}")
        return filepath
        
    except Exception as e:
        print(f"íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

def fetch_and_process_data(year: int, item_name: str) -> bool:
    """ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜"""
    print(f"\n{'='*50}")
    print(f"  {year}ë…„ {item_name} ë°ì´í„° ì²˜ë¦¬ ì‹œì‘")
    print(f"{'='*50}")
    
    # ì…ë ¥ ê²€ì¦
    if item_name not in COMMODITY_MAP:
        print(f"ì˜¤ë¥˜: '{item_name}'ì€(ëŠ”) ìœ íš¨í•œ í’ˆëª©ì´ ì•„ë‹™ë‹ˆë‹¤.")
        print(f"ì‚¬ìš© ê°€ëŠ¥í•œ í’ˆëª©: {list(COMMODITY_MAP.keys())}")
        return False
    
    # ì¶œë ¥ ë””ë ‰í„°ë¦¬ í™•ì¸
    ensure_output_directory()
    
    # êµ­ê°€ ì¤‘ì‹¬ì  ë°ì´í„° ì¤€ë¹„
    country_centroids = get_country_centroids()
    if country_centroids is None:
        print("êµ­ê°€ ë°ì´í„°ë¥¼ ë¡œë”©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    # UN Comtrade APIì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    commodity_code = COMMODITY_MAP[item_name]
    trade_data = fetch_trade_data(year, commodity_code)
    if trade_data is None or trade_data.empty:
        print("ë¬´ì—­ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    # ë°ì´í„° ì „ì²˜ë¦¬
    processed_data = process_trade_data(trade_data, country_centroids)
    if processed_data is None or processed_data.empty:
        print("ë°ì´í„° ì „ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return False
    
    # GeoJSON ìƒì„±
    geojson = create_geojson(processed_data, item_name, year)
    if geojson is None:
        print("GeoJSON ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return False
    
    # íŒŒì¼ ì €ì¥
    filepath = save_geojson(geojson, item_name, year)
    if filepath is None:
        print("íŒŒì¼ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return False
    
    print(f"\nâœ… ì²˜ë¦¬ ì™„ë£Œ!")
    print(f"   - íŒŒì¼: {filepath}")
    print(f"   - ë¬´ì—­ íë¦„ ìˆ˜: {len(geojson['features'])}")
    
    return True

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="UN Comtrade ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ì—¬ GeoJSONìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python process_trade_data.py --year 2023 --item semiconductor
  python process_trade_data.py --year 2019 --item oil
  python process_trade_data.py --year 2022 --item copper
  python process_trade_data.py --year 2021 --item plastic

í’ˆëª© ì˜µì…˜:
  semiconductor : ë°˜ë„ì²´ (HS Code: 8541,8542)
  oil          : ì›ìœ  (HS Code: 2709)  
  copper       : êµ¬ë¦¬ (HS Code: 7403)
  plastic      : í”Œë¼ìŠ¤í‹± (HS Code: 3901,3902,3903)
        """
    )
    
    parser.add_argument(
        "--year", 
        type=int, 
        required=True, 
        help="ë°ì´í„°ë¥¼ ì¡°íšŒí•  ì—°ë„ (ì˜ˆ: 2023)"
    )
    
    parser.add_argument(
        "--item", 
        type=str, 
        required=True, 
        choices=list(COMMODITY_MAP.keys()), 
        help="ë°ì´í„°ë¥¼ ì¡°íšŒí•  í’ˆëª©"
    )
    
    args = parser.parse_args()
    
    # ì²˜ë¦¬ ì‹¤í–‰
    success = fetch_and_process_data(args.year, args.item)
    
    if success:
        print(f"\nğŸ‰ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        sys.exit(0)
    else:
        print(f"\nâŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        sys.exit(1)

if __name__ == "__main__":
    main()
